{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_features.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def avg_and_std(scores):\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Function for k-fold cross-validation with optional PCA\n",
    "def k_fold_cv(model, df, metric_funcs, n_splits=5):\n",
    "    X = df.iloc[:, 2:].values  # Features\n",
    "    y = df.iloc[:, 1].values   # Target\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = {metric_func.__name__: [] for metric_func in metric_funcs}\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate and store each metric\n",
    "        for metric_func in metric_funcs:\n",
    "            score = metric_func(y_test, y_pred)\n",
    "            scores[metric_func.__name__].append(score)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "# Parameter combination test\n",
    "for crit in [\"gini\", \"entropy\", \"log_loss\"]:\n",
    "    for n_est in range(25, 201, 25):\n",
    "        for m_depth in range(5, 106, 10):\n",
    "            for m_samples_leaf in range(5, 26, 5):\n",
    "                params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': m_depth,\n",
    "                    'min_samples_leaf': m_samples_leaf,\n",
    "                    'criterion': crit\n",
    "                }\n",
    "                \n",
    "                # Initialize model with current parameters\n",
    "                rf_model = RandomForestClassifier(**params)\n",
    "                \n",
    "                # Perform cross-validation and get AUC scores\n",
    "                score = k_fold_cv(model=rf_model, df=df, metric_funcs=[roc_auc_score])\n",
    "                avg_auc, std_auc = avg_and_std(np.array(score[\"roc_auc_score\"]))\n",
    "                \n",
    "                # Update best parameters if new best AUC is found\n",
    "                if avg_auc > best_auc:\n",
    "                    best_auc = avg_auc\n",
    "                    best_params = params\n",
    "                    print(\"New best parameter combination found!\")\n",
    "                    for parameter, value in best_params.items():\n",
    "                        print(f\"\\t{parameter}: {value}\")\n",
    "                    print(f\"Best Average AUC: {best_auc * 100:.6f}%\\n\")\n",
    "                else:\n",
    "                    print(\"Parameter combination tested:\")\n",
    "                    for parameter, value in params.items():\n",
    "                        print(f\"\\t{parameter}: {value}\")\n",
    "                    print(f\"Average AUC: {avg_auc * 100:.6f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final best parameters and AUC\n",
    "print(\"Best parameter combination:\")\n",
    "for parameter, value in best_params.items():\n",
    "    print(f\"\\t{parameter}: {value}\")\n",
    "print(f\"Best Average AUC: {best_auc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
